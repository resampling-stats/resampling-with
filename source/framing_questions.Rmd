---
jupyter:
  jupytext:
    metadata_filter:
      notebook:
        additional: all
        excluded:
        - language_info
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 0.8.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
resampling_with:
    ed2_fname: 18-Chap-14
---

```{r setup, include=FALSE}
source("_common.R")
```

# Framing Statistical Questions {#sec-framing-questions}

## Introduction

@sec-what-is-probability - @sec-monte-carlo discussed problems in probability
theory. That is, we have been estimating the probability of a composite event
*resulting from a system in which we know the probabilities of the simple
events* — the "parameters" of the situation.

Then @sec-inference-ideas - @sec-point-estimation discussed the underlying
philosophy of statistical inference.

Now we turn to inferential-statistical problems. Up until now, we have
been estimating the complex probabilities of *known* universes — the
topic of *probability*.  Now as we turn to problems in *statistics*, we
seek to learn the characteristics of an unknown system — the basic
probabilities of its simple events and parameters. (Here we note again,
however, that in the process of dealing with them, all
statistical-inferential problems eventually are converted into problems
of pure probability). To assess the characteristics of the system in
such problems, we employ the characteristics of the sample(s) that have
been drawn from it.

For further discussion on the distinction between inferential statistics and
probability theory, see @sec-resampling-method - @sec-what-is-probability.

This chapter begins the topic of *hypothesis testing*.  The issue is:
whether to adjudge that a particular sample (or samples) come(s) from a
particular universe. A two-outcome yes-no universe is discussed first.
Then we move on to "measured-data" universes, which are more complex
than yes-no outcomes because the variables can take on many values, and
because we ask somewhat more complex questions about the relationships of the
samples to the universes. This topic is continued in subsequent chapters.

In a typical hypothesis-testing problem presented in this chapter, one
sample of hospital patients is treated with a new drug and a second
sample is not treated but rather given a "placebo." After obtaining
results from the samples, the "null" or "test" or "benchmark" hypothesis
would be that the resulting drug and placebo samples are drawn from the
same universe. This device of the null hypothesis is the equivalent of
stating that the drug had no effect on the patients. It is a special
intellectual strategy developed to handle such statistical questions.

We start with the scientific question: Does the medicine have an effect?
We then translate it into a testable statistical question: How likely is
it that the sample means come from the same universe? This process of
question-translation is the crucial step in hypothesis-testing and
inferential statistics. The chapter then explains how to solve these
problems using resampling methods after you have formulated the proper
statistical question.

Though the examples in the chapter mostly focus on tests of hypotheses,
the procedures also apply to confidence intervals, which will be
discussed later.

## Translating scientific questions into probabilistic and statistical questions

The first step in using probability and statistics is to translate the
*scientific* question into a *statistical* question. Once you know
exactly which prob-stats question you want to ask — that is, exactly
which probability you want to determine — the rest of the work is
relatively easy (though subtle). The stage at which you are most likely
to make mistakes is in stating the question you want to answer in
probabilistic terms.

Though this translation is difficult, it involves no mathematics.
Rather, this step requires only hard thought. You cannot beg off by
saying, "I have no brain for math!" The need is for a brain that will do
clear thinking, rather than a brain especially talented in mathematics.
A person who uses conventional methods can avoid this hard thinking by
simply grabbing the formula for some test without understanding why s/he
chooses that test. But resampling pushes you to do this thinking
explicitly.

This crucial process of translating from a pre-statistical question to a
statistical question takes place in all statistical inference. But its
nature comes out most sharply with respect to testing hypotheses, so
most of what will be said about it will be in that context.

## The three types of questions

Let's consider the natures of conceptual, operational, and statistical
questions.

### The Scientific Question

A study for either scientific or decision-making purposes properly begins with
a general question about the nature of the world — that is, a conceptual or
theoretical question. One must then transform this question into an
operational-empirical form that one can study scientifically. Thence comes the
translation into a technical-statistical question.

The scientific-conceptual-theoretical question can be an issue of theory, or a
policy choice, or the result of curiosity at large.

Examples include: Can a bioengineer increase the chance of female calves being
born? Is copper becoming less scarce? Are the prices of liquor systematically
different in states where the liquor stores are publicly owned compared to
states where they are privately owned? Does a new formulation of pig rations
lead to faster hog growth? Was the rate of unemployment higher last month than
the long-run average, or was the higher figure likely to be the result of
sampling error? What are the margins of probable error for an unemployment
survey?

### The Operational-Empirical Question

*The operational-empirical question* is framed in measurable quantities in a
meaningful design. Examples include: How likely is this state of affairs (say,
the new pig-food formulation) to cause an event such as was observed (say, the
observed increase in hog growth)? How likely is it that the mean unemployment
rate of a sample taken from the universe of interest (say, the labor force,
with an unemployment rate of 10 percent) will be between 11 percent and 12
percent? What is the probability of getting three girls in the first four
children if the probability of a girl is .48? How unlikely is it to get nine
females out of ten calves in an experiment on your farm? Did the price of
copper fall between 1800 and the present? These questions are in the form of
empirical questions, which have already been transformed by operationalizing
from scientific-conceptual questions.

### The Statistical Question

At this point one must decide whether the conceptual-scientific question is of
the form of either a) or b):

a.  A test about whether some sample will frequently happen by chance
    rather than being very surprising — a test of the "significance" of
    a hypothesis. Such hypothesis testing takes the following form: How
    likely is a given "universe" to produce *some* sample like x? This
    leads to interpretation about: How likely is a given universe to be
    the cause of *this observed* sample?
b.  A question about the accuracy of the estimate of a parameter of the
    population based upon sample evidence (an inquiry about "confidence
    intervals"). This sort of question is considered by some (but not by
    me) to be a question in estimation — that is, one's best guess
    about (say) the magnitude and probable error of the mean or median
    of a population. This is the form of a question about confidence
    limits — how likely is the mean to be between x and y?

Notice that the statistical question is framed as a question in probability.

## Illustrative translations

The best way to explain how to translate a scientific question into a
statistical question is to illustrate the process.

### Illustration A — beliefs about smoking

Were doctors' beliefs as of 1964 about the harmfulness of cigarette smoking
(and doctors' own smoking behavior) affected by the *social* groups among whom
the doctors live [@simon1967doctors]? That was the *theoretical* question. We
decided to define the doctors' *reference groups* as the *states* in which they
live, because data about doctors and smoking were available state by state
(*Modern Medicine*, 1964). We could then translate this question into an
operational and testable *scientific* hypothesis by asking this question: Do
doctors in tobacco-economy states differ from doctors in other states in their
smoking, and in their beliefs about smoking?

Which numbers would help us answer this question, and how do we interpret those
numbers? We now were ready to ask the *statistical* question: Do doctors in
tobacco-economy states "belong to the same universe" (with respect to smoking)
as do other doctors? That is, do doctors in tobacco-economy states have the
same characteristics — at least, those characteristics we are interested in,
smoking in this case — as do other doctors? Later we shall see that the way to
proceed is to consider the statistical hypothesis that these doctors do indeed
belong to that same universe; that hypothesis and the universe will be called
"benchmark hypothesis" and "benchmark universe" respectively — or in more
conventional usage, the "null hypothesis."

If the tobacco-economy doctors do indeed belong to the benchmark universe —
that is, if the benchmark hypothesis is correct — then there is a 49/50 chance
that doctors in some state *other than* the state in which tobacco is most
important will have the highest rate of cigarette smoking. But in fact we
observe that the state in which tobacco accounts for the largest proportion of
the state's income — North Carolina — had (as of 1964) a higher proportion of
doctors who smoked than any other state. (Furthermore, a lower proportion of
doctors in North Carolina than in any other state said that they *believed*
that smoking is a health hazard.)

Of course, it is possible that it was just *chance* that North Carolina doctors
smoked most, but the chance is only 1 in 50 if the benchmark hypothesis is
correct. Obviously, *some* state had to have the highest rate, and the chance
for any other state was also 1 in 50. But, because our original *scientific*
hypothesis was that North Carolina doctors' smoking rate would be highest, and
we then observed that it was highest even though the chance was only 1 in 50,
the observation became interesting and meaningful to us. It means that the
chances are strong that there was a connection between the importance of
tobacco in the economy of a state and the rate of cigarette smoking among
doctors living there (as of 1964).

To consider this problem from another direction, it would be rare for North
Carolina to have the highest smoking rate for doctors if there were no special
reason for it; in fact, it would occur only once in fifty times. But, if there
*were* a special reason — and we hypothesize that the tobacco economy provides
the reason — then it would *not* seem unusual or rare for North Carolina to
have the highest rate; therefore we choose to believe in the not-so-unusual
phenomenon, that the tobacco economy caused doctors to smoke cigarettes.

Like many (most? all?) actual situations, the cigarettes and doctors' smoking
issue is a rather messy business. Did I have a clear-cut, theoretically-derived
prediction before I began? Maybe I did a bit of "data dredging" — that is,
maybe I started with a vague expectation, and only arrived at my sharp
hypothesis after I saw the data. This would weaken the probabilistic
interpretation of the test of significance — but this is something that a
scientific investigator does not like to do because it weakens his/her claim
for attention and chance of publication. On the other hand, if one were a
Bayesian, one could claim that one had a prior probability that the observed
effect would occur, and the observed data strengthens that prior; but this
procedure would not seem proper to many other investigators. The only wholly
satisfactory conclusion is to obtain more data — but as of 1993, there does not
seem to have been another data set collected since 1964, and collecting a set
by myself is not feasible.

This clearly is a case of statistical inference that one could argue about,
though perhaps it is true that *all* cases where the data are sufficiently
ambiguous as to require a test of significance are also sufficiently ambiguous
that they are properly subject to argument.

For some decades the hypothetico-deductive framework was the leading point of
view in empirical science. It insisted that the empirical and statistical
investigation should be preceded by theory, and only propositions suggested by
the theory should be tested. Investigators were not supposed to go back and
forth from data to theory to testing. It is now clear that this is an
ivory-tower irrelevance, and no one lived by the hypothetico-deductive
strictures anyway — just pretended to. Furthermore, there is no sound reason to
feel constrained by it, though it strengthens your conclusions if you had
theoretical reason in advance to expect the finding you obtained.

### Illustration B — is it a cure?

Does medicine CCC cure some particular cancer? That's the scientific question.
So you give the medicine to six patients who have the cancer and you do not
give it to six similar patients who have the cancer. Your sample contains only
twelve people because it is not feasible for you to obtain a larger sample.
Five of six "medicine" patients get well, two of six "no medicine" patients get
well. Does the medicine cure the cancer? That is, if future cancer patients
take the medicine, will their rate of recovery be higher than if they did not
take the medicine?

One way to translate the scientific question into a statistical question is to
ask: Do the "medicine" patients *belong to the same universe* as the "no
medicine" patients? That is, we ask whether "medicine" patients still have the
*same* chances of getting well from the cancer as do the "no medicine"
patients, or whether the medicine has bettered the chances of those who took it
and thus removed them from the original universe, with its original chances of
getting well. The original universe, to which the "no medicine" patients must
still belong, is the benchmark universe. Shortly we shall see that we proceed
by comparing the observed results against the benchmark *hypothesis* that the
"medicine" patients still belong to the benchmark *universe* — that is, they
still have the same chance of getting well as the "no medicine" patients.

We want to know whether or not the medicine does any good. This question is the
same as asking whether patients who take medicine are still in the same
population (universe) as "no medicine" patients, or whether they now belong to
a different population in which patients have higher chances of getting well.
To recapitulate our translations, we move from asking: Does the medicine cure
the cancer? to, Do "medicine" patients have the same chance of getting well as
"no medicine" patients?; and finally, to: Do "medicine" patients belong to the
same universe (population) as "no medicine" patients? Remember that
"population" in this sense does not refer to the population at large, but
rather to a group of cancer sufferers (perhaps an infinitely large group) who
have given chances of getting well, on the average. Groups with different
chances of getting well are called "different populations" (universes). Shortly
we shall see how to *answer* this statistical question. We must keep in mind
that our ultimate concern in cases like this one is to *predict future results*
of the medicine, that is, to predict whether use of the medicine will lead to a
higher recovery rate than would be observed without the medicine.

### Illustration C — a better method for teaching reading

Is method Alpha a better method of teaching reading than method Beta? That is,
will method Alpha produce a higher average reading score in the future than
will method Beta? Twenty children taught to read with method Alpha have an
average reading score of 79, whereas children taught with method Beta have an
average score of 84. To translate this *scientific* question into a
*statistical* question we ask: Do children taught with method Alpha come from
the same universe (population) as children taught with method Beta? Again,
"universe" (population) does *not* mean the town or social group the children
come from, and indeed the experiment will make sense only if the children *do*
come from the same population, in that sense of "population." What we want to
know is whether or not the children belong to the same *statistical* population
(universe), *defined according to their reading ability, after they have
studied* with method Alpha or method Beta.

### Illustration D — better fertilizer

If one plot of ground is treated with fertilizer, and another similar plot is
not treated, the benchmark (null) hypothesis is that the corn raised on the
treated plot is no different than the corn raised on the untreated lot — that
is, that the corn from the treated plot comes from ("belongs to") the same
universe as the corn from the untreated plot. If our statistical test makes it
seem very unlikely that a universe like that from which the untreated-plot corn
comes would *also* produce corn such as came from the treated plot, then we are
willing to believe that the fertilizer has an effect. For a psychological
example, substitute the words "group of children" for "plot," "special
training" for "fertilizer," and "I.Q. score" for "corn."

There is nothing sacred about the benchmark (null) hypothesis of "no
difference." You could just as well test the benchmark hypothesis that the corn
comes from a universe that averages 110 bushels per acre, if you have reason to
be especially interested in knowing whether or not the fertilizer produces more
than 110 bushels per acre. But in many cases it is reasonable to test the
probability that a sample comes from the population that does not receive the
special treatment of medicine, fertilizer, or training.

## Generalizing from sample to universe

So far we have discussed the scientific question and the statistical question.
Remember that there is always a generalization question, too: Do the
statistical results from this particular sample of, say, rats apply to a
universe of humans? This question can be answered only with wisdom, common
sense, and general knowledge, and not with probability statistics.

Translating from a scientific question into a statistical question is mostly a
matter of asking the probability that some given benchmark universe
(population) will produce one or more observed samples. Notice that we must (at
least for general scientific testing purposes) ask about a *given* universe
whose composition we assume to be *known*, rather than about a *range* of
universes, or about a universe whose properties are unknown. In fact, there is
really only one question that probability statistics can answer: Given some
particular benchmark universe of some stated composition, what is the
probability that an observed sample would come from it? (Please notice the
subtle but all-important difference between the words "would come" in the
previous sentence, and the word "came.") A variation of this question is: Given
two (or more) samples, what is the probability that they would come from the
*same* universe — that is, that the same universe would produce both of them?
In this latter case, the relevant benchmark universe is implicitly the universe
whose composition is the two samples combined.

The necessity for stating the characteristics of the universe in question
becomes obvious when you think about it for a moment. Probability-statistical
testing adds up to comparing a sample with a particular benchmark universe, and
asking whether there probably is a difference between the sample and the
universe. To carry out this comparison, we ask *how likely* it is that the
benchmark universe would produce a sample like the observed sample.

<!---
improve phrasing
-->

But in order to find out whether or not a universe could produce a given
sample, we must ask whether or not some *particular* universe — with stated
characteristics — could produce the sample. There is no doubt that *some*
universe could produce the sample by a random process; in fact, some universe
did. The only sensible question, then, is whether or not a *particular*
universe, with stated (or known) characteristics, is likely to produce such a
sample. In the case of the medicine, the universe with which we compare the
sample who took the medicine is the benchmark universe to which that sample
would belong if the medicine had had no effect. This comparison leads to the
benchmark (null) hypothesis that the sample comes from a population in which
the medicine (or other experimental treatment) seems to have *no effect*.  It
is to avoid confusion inherent in the term "null hypothesis" that I replace it
with the term "benchmark hypothesis."

The concept of the benchmark (null) hypothesis is not easy to grasp. The best
way to learn its meaning is to see how it is used in practice. For example, we
say we are willing to believe that the medicine has an effect if it seems very
unlikely from the number who get well that the patients given the medicine
still belong to the same benchmark universe as the patients given no medicine
at all — that is, if the benchmark hypothesis is unlikely.

## The steps in statistical inference

These are the steps in conducting statistical inference

* **Step 1.** Frame a question in the form of: *What is the chance of getting
  the observed sample x from some specified population X?* For example, what is
  the probability of getting a sample of 9 females and one male from a
  population where the probability of getting a single female is .48?
* **Step 2.** Reframe the question in the form of: *What kinds of samples does
  population X produce, with which probabilities?* That is, what is the
  probability of the observed sample x (9 females in 10 calves), given that a
  population is X (composed of 48 percent females)? Or in notation, what is
  $P(x | X)$?
* **Step 3.** Actually *investigate the behavior* of S with respect to S and
  other samples. This can be done in two ways:

 1. Use the calculus of probability (the formulaic method), perhaps resorting
    to the Monte Carlo method if an appropriate formula does not exist. Or
 2. Resampling (in the larger sense), which equals the Monte Carlo method minus
    its use for approximations, investigation of complex functions in
    statistics and other theoretical mathematics, and non-resampling uses
    elsewhere in science. Resampling in the more restricted sense includes
    bootstrap, permutation, and other non-parametric methods. More about the
    resampling procedure follows in the paragraphs to come, and then in later
    chapters in the book.
<!---
Some repetition in para above?
-->
* **Step 4.** Interpret the probabilities that result from step 3 in terms of
  acceptance or rejection of hypotheses, surety of conclusions, and as inputs
  to decision theory.[^resampling-philosophy]

[^resampling-philosophy]: These steps are discussed in more philosophic depth
    in my (JLS's) [online book on the philosophy of statistics and
    resampling](http://www.juliansimon.org/writings/Resampling_Philosophy).

The following short definition of statistical inference summarizes the previous
four steps:

> Statistical inference equals the selection of a probabilistic model
to resemble the process you wish to investigate, the investigation of that
model's behavior, and the interpretation of the results.

Stating the steps to be followed in a procedure is an operational definition of
the procedure. My belief in the clarifying power of this device (the
operational definition) is embodied in the set of steps given in
@sec-monte-carlo for the various aspects of statistical inference. A canonical
question-and-answer procedure for testing hypotheses will be found in
@sec-testing-procedures, and one for confidence intervals will be found in
@sec-confidence-accuracy.

## Summary

We define resampling to include problems in inferential statistics as well as
problems in probability as follows: *Using the entire set of data you have in
hand, or using the given data-generating mechanism (such as a die) that is a
model of the process you wish to understand, produce new samples of simulated
data, and examine the results of those samples*. That's it in a nutshell. In
some cases, it may also be appropriate to amplify this procedure with
additional assumptions.

Problems in pure probability may at first seem different in nature than
problems in statistical inference. But the same logic as stated in this
definition applies to both varieties of problems. The difference is that in
probability problems the "model" is known in advance — say, the model implicit
in a deck of poker cards plus a game's rules for dealing and counting the
results — rather than the model being assumed to be best estimated by the
observed data, as in resampling statistics.

The hardest job in using probability statistics, and the most important, is to
*translate* the scientific question into a form to which statistics can give a
sensible answer. You must translate scientific questions into the appropriate
form for *statistical operations*, so that you know which operations to
perform. This is the part of the job that requires hard, clear thinking —
though it is non-mathematical thinking — and it is the part that someone else
usually cannot easily do for you.

Once you know exactly which probability-statistical question you want to ask —
that is, exactly which probability you want to determine — the rest of the work
is relatively easy. The stage at which you are most likely to make mistakes is
in stating the question you want to answer in probabilistic terms. Though this
step is hard, *it involves no mathematics*.  This step requires only *hard,
clear thinking*.  You cannot beg off by saying "I have no brain for math!" To
flub this step is to admit that you have no brain for clear thinking, rather
than no brain for mathematics.
