---
jupyter:
  jupytext:
    metadata_filter:
      notebook:
        additional: all
        excluded:
        - language_info
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 0.8.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
resampling_with:
    ed2_fname: ""
---

```{r setup, include=FALSE}
source("_common.R")
```

# The Monty Hall problem

The Monty Hall Problem is a probability problem that is famous for its
deceptive simplicity.  It has its own long Wikipedia page:
<https://en.wikipedia.org/wiki/Monty_Hall_problem>.

Here is the problem in its most famous form; a letter to the columnist
[Marilyn vos Savant](https://en.wikipedia.org/wiki/Marilyn_vos_Savant),
published in Parade Magazine [-@savant1990monty]:

> Suppose you’re on a game show, and you’re given the choice of three doors.
> Behind one door is a car, behind the others, goats. You pick a door, say #1,
> and the host, who knows what’s behind the doors, opens another door, say #3,
> which has a goat. He says to you, "Do you want to pick door #2?" Is it to
> your advantage to switch your choice of doors?

In fact the first person to propose (and solve) this problem was Steve Selvin,
a professor of public health at the University of California, Berkeley
[@slevin1975monty].

Most people, including at least one of us, your humble authors, quickly come to
the wrong conclusion.  The most common but incorrect answer is that it will
make no difference if you switch doors or stay with your original choice.  The
obvious intuition is that, after Monty opens his door, there are two doors that
might have the car behind them, and therefore, a 50% chance it will be behind
any one of the two. It turns out that answer is wrong; you will double your
chances of winning by switching doors. Did you get the answer right?

If you got the answer wrong, you are in excellent company.  As you can see
from the commentary in @savant1990monty, many mathematicians wrote to Parade
magazine to assert that the (correct) solution was wrong.  [Paul
Erdős](https://en.wikipedia.org/wiki/Paul_Erd%C5%91s) was one of the most
famous mathematicians of the 20th century; he could not be convinced of the
correct solution until he had seen a computer simulation [@vazsonyi1999door],
of the type we will do below.

To simulate a trial of this problem, we need to select a door at random to
house the car, and another door at random, to be the door the contestant
chooses.  We number the doors 1, 2 and 3.   Now we need two random choices
from the options 1, 2 or 3, one for the door with the car, the other for the
contestant door.  To chose a door for the car, we could throw a die, and chose
door 1 if the die shows 1 or 4, door 2 if the die shows 2 or 5, and door 3 for
3 or 6.  Then we throw the die again to chose the contestant door.

But throwing dice is a little boring; we have to find the die, then throw it
many times, and record the results.   Instead we can ask the computer to chose
the doors at random.

```{r, echo=FALSE}
n_trials <- 25
```

For this simulation, let us do `r n_trials` trials.  We ask the computer to
create two sets of `r n_trials` random numbers from 1 through 3. The first set
is the door with the car behind it ("Car door").  The second set have the door
that the contestant chose at random ("Our door").   We put these in a table,
and make some new, empty columns to fill in later.  The first new column is
"Monty opens".  In due course, we will use this column to record the door that
Monty Hall will open on this trial.  The last two columns express the outcome.
The first is "Stay wins".  This has "Yes" if we win on this trial by sticking
to our original choice of door, and "No" otherwise.  The last column is
"Switch wins". This has "Yes" if we win by switching doors, and "No"
otherwise. See table @tbl-montyblank).

```{python, echo=FALSE}
# Need Python for random numbers that are predictable across platforms.
import numpy as np
import pandas as pd

np.random.seed(2028)   # 2028 chosen such that it generates [3, 3] then [3, 1]
n_trials = int(r.n_trials)
random_matrix = np.random.randint(1, 4, size=(n_trials, 2))
df = pd.DataFrame(random_matrix)
df.columns = ('Car door', 'Our door')
# Set the columns to fill in later.
# It would be more efficient to use `df.assign` here, but less readable.
df['Monty opens'] = ''
df['Stay wins'] = ''
df['Switch wins'] = ''
```

```{r, montyblank, echo=FALSE}
blank_df <- tibble::as_tibble(py$df)
knitr::kable(blank_df,
  booktabs = TRUE,
  row.names = TRUE,
  caption = sprintf('%d simulations of the Monty Hall problem
                    {#tbl-montyblank}', n_trials)
)
```

```{r, echo=FALSE}
# Do the calculation
fdf <- blank_df
# Convert Monty opens column to integer, for car door number.
fdf['Monty opens'] <- as.integer(NA)
# Cycle over each row in the original data frame.
for (i in 1:dim(fdf)[1]) {
    car_door <- fdf[i, 'Car door']
    our_door <- fdf[i, 'Our door']
    # Remove our door from consideration.  There are two doors remaining.
    remaining_doors <- setdiff(1:3, our_door)
    if (our_door == car_door) {   # Our door does match car door.
        fdf[i, 'Stay wins'] <- 'Yes'
        fdf[i, 'Switch wins'] <- 'No'
        # Choose one of the remaining (goat) doors at random.
        fdf[i, 'Monty opens'] <- sample(remaining_doors, 1)
    } else {  # our door did not match.
        fdf[i, 'Stay wins'] <- 'No'
        # Monty must open the remaining door that isn't the car door.
        fdf[i, 'Monty opens'] <- setdiff(remaining_doors, car_door)
        # The only one left is the car door.
        fdf[i, 'Switch wins'] <- 'Yes'
    }
}
```

```{r, echo=FALSE}
# Check our assumptions, below.
stopifnot(all(fdf[1, 1:2] == c(3, 3)))
stopifnot(all(fdf[2, 1:2] == c(3, 1)))
# Not this one, apparently.
# stopifnot(fdf[1, 3] == 2)
```

In the first trial in @tbl-montyblank), the computer selected door 3 for
car, and door 3 for the contestant.  Now Monty must open a door, and he cannot
open our door (door 3) so he has the choice of opening door 1 or door 2; he
chooses randomly, and opens door 2.  On this trial, we win if we stay with our
original choice, and we lose if we change to the remaining door, door 1.

Now we go the second trial.  The computer chose door 3 for the car, and door 1 for our choice.  Monty cannot choose our door (door 1) or the door with the car behind it (door 3), so he must open door 2.   Now if we stay with our original choice, we lose, but if we switch, we win.

You may want to print out table @tbl-montyblank, and fill out the blank
columns, to work through the logic.

After doing a few more trials, and some reflection, you may see that there are
two different situations here: the situation when our *initial guess was
right*, and the situation where our *initial guess was wrong*.   When our
initial guess was right, we win by staying with our original choice, but when
it was wrong, we always win by switching.   The chance of our *initial guess*
being correct is 1/3 (one door out of three).  So the chances of winning by
staying are 1/3, and the chances of winning by switching are 2/3.  But
remember, you don't need to follow this logic to get the right answer.  As you
will see below, the resampling simulation shows us that the Switch strategy
wins.

Table @tbl-montyfull is a version of table @tbl-montyblank for
which we have filled in the blank columns using the logic above.

```{r, montyfull, echo=FALSE}
knitr::kable(fdf,
  booktabs = TRUE,
  row.names = TRUE,
  caption = sprintf('%d simulations of the Monty Hall problem, filled out
  {#tbl-montyfull}', n_trials)
)
```

The proportion of times "Stay" wins in these `r n_trials` trials is
`r sum(fdf['Stay wins'] == 'Yes') / n_trials`.
The proportion of times "Switch" wins is
`r sum(fdf['Switch wins'] == 'Yes') / n_trials`; the Switch strategy wins about twice as often as the Stay strategy.

Doing these simulations has two large benefits.   First, it gives us the right answer, saving us from making a mistake.  Second, the process of simulation forces us to think about how the problem works.  This can give us better understanding, and make it easier to reason about the solution.

We will soon see that these same advantages also apply to reasoning about
statistics.
